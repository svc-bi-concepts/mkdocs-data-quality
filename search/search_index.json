{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Data Governance","text":"<p>Data Governance for Shared Databases </p>"},{"location":"data-governance-shared-databases/","title":"Data Governance for Shared Databases","text":""},{"location":"data-governance-shared-databases/#dbt","title":"DBT","text":"<ul> <li>Data Quality Tests: Implement DQ tests for shared databases using generic DBT tests</li> <li>Data Contracts: Enforce contracts all DM models (enforce in project file for DM folder)</li> </ul>"},{"location":"data-governance-shared-databases/#snowflake-only","title":"Snowflake Only","text":"<ul> <li>Data Quality Tests: Implement DQ tests for shared databases:<ul> <li>Not nulls implement as table constraints</li> <li>Other tests implement as DMF DQ Tests possibly utilising Tasks and Streams</li> </ul> </li> <li>Data Contracts: Currently not directly supported in Snowflake</li> </ul>"},{"location":"data-governance-shared-databases/#data-quality-tools","title":"Data Quality Tools","text":"<p>If using dedicated  Data Quality or Governance tools such as Soda or Great Expectations;</p> <ul> <li> <p>Data Quality Tests: Implement  DQ tests for shared databases using the relevent proprietary method</p> </li> <li> <p>Data Contracts can be enforced with a combination of Schema enforcement (column names, types, nullability) and Data Quality Rules (valid ranges, uniqueness, freshness) e.g. Soda example yaml checks</p> </li> </ul>"},{"location":"data-quality-tests-DBT/","title":"Data Quality Tests in DBT","text":"<p>Configured in yaml files for each model.</p>"},{"location":"data-quality-tests-DBT/#not-null","title":"NOT NULL","text":"<p>At column level</p> <pre><code>columns:\n    - name: your_column\n    data_type: TEXT\n    description: Business key for something\n    tests:\n        - not_null  \n</code></pre>"},{"location":"data-quality-tests-DBT/#unique","title":"Unique","text":""},{"location":"data-quality-tests-DBT/#unique-single-column","title":"Unique Single Column","text":"<p>At column level</p> <pre><code>columns:\n    - name: your_column\n    data_type: TEXT\n    description: Business key for something\n    tests:\n        - unique\n</code></pre>"},{"location":"data-quality-tests-DBT/#unique-combination-of-columns","title":"Unique Combination of Columns","text":"<p>At model level - using package dbt-labs/dbt_utils</p> <pre><code>models:\n  - name: your_model\n    tests:\n      - dbt_utils.unique_combination_of_columns:\n          combination_of_columns:\n           - column1 \n           - column2\n           - column3\n</code></pre>"},{"location":"data-quality-tests-DBT/#referential-integrity","title":"Referential Integrity","text":"<p>At column level</p> <pre><code>columns:\n    - name: your_column\n      data_tests:\n       - relationships:\n            to: ref('ref_model')\n            field: column_in_ref_model\n</code></pre>"},{"location":"data-quality-tests-DBT/#equal-rowcount","title":"Equal Rowcount","text":"<p>At model level - using package dbt-labs/dbt_utils</p> <pre><code>models:\n  - name: your_model\n    tests:\n      - dbt_utils.equal_rowcount:\n          compare_model: ref('ref_model')\n</code></pre>"},{"location":"data-quality-tests-DBT/#test-for-tests","title":"Test for tests","text":"<p>At project folder level (in dbt_project.yml) - using calogica/dbt_expectations</p> <pre><code>models:\n  your_project:\n    your_sub_folder:\n      +required_tests: {\"unique_combination_of_columns\" : 1}\n</code></pre>"},{"location":"data-quality-tests-shared-databases/","title":"Data Quality Tests for Shared Database","text":""},{"location":"data-quality-tests-shared-databases/#data-mart","title":"Data Mart","text":""},{"location":"data-quality-tests-shared-databases/#test-on-one-database-object","title":"Test on One Database Object","text":"<ul> <li>Grain of table: key/unique combo of columns \u2013test_coverage e.g.\"unique_combination_of_columns|unique\" : 1</li> <li>Not nulls \u2013 generally all columns in a data mart should not be null \u2013 use default values instead (\u201cN/A\u201d, \u201cunknown\u201d..)</li> <li>Accepted values</li> </ul>"},{"location":"data-quality-tests-shared-databases/#test-how-one-database-object-refers-to-another-database-object","title":"Test how One Database Object refers to another Database Object","text":"<ul> <li>Referential integrity : facts to dims</li> <li>Row count consistency between source and transformed tables</li> </ul>"},{"location":"data-quality-tests-shared-databases/#test-something-unique-about-your-data","title":"Test Something Unique about Your Data","text":"<ul> <li>Test for specific business rules</li> </ul>"},{"location":"data-quality-tests-shared-databases/#test-the-freshness-of-your-raw-source-data","title":"Test the Freshness of your Raw Source Data","text":"<ul> <li>Freshness tests on raw sources</li> </ul>"},{"location":"data-quality-tests-shared-databases/#test-coverage-test-for-tests","title":"Test Coverage: Test for Tests","text":"<ul> <li>For each model test for existence of unique test </li> </ul>"},{"location":"data-quality-tests-snowflake-only/","title":"Data Quality Tests using Snowflake Data Metric Functions (DMFs)","text":"<p>Requires Enterprise Edition Snowflake license.</p>"},{"location":"data-quality-tests-snowflake-only/#specific-data-quality-tests-using-dmfs","title":"Specific Data Quality tests using DMFs","text":""},{"location":"data-quality-tests-snowflake-only/#not-null","title":"NOT NULL","text":"NOT NULL<pre><code>--Manually test system DMF \nSELECT SNOWFLAKE.CORE.NULL_COUNT(\n  SELECT first_name\n  FROM YOUR_DATABASE.YOUR_SCHEMA.YOUR_TABLE\n);\n\n--Apply to table\nALTER TABLE YOUR_DATABASE.YOUR_SCHEMA.YOUR_TABLE\n  ADD DATA METRIC FUNCTION SNOWFLAKE.CORE.NULL_COUNT\n    ON (first_name);\n</code></pre>"},{"location":"data-quality-tests-snowflake-only/#unique","title":"Unique","text":""},{"location":"data-quality-tests-snowflake-only/#unique-single-column","title":"Unique Single Column","text":"Unique test single column<pre><code>--manually test system DMF\nSELECT snowflake.core.duplicate_count(\n  SELECT account_number\n  FROM YOUR_DATABASE.YOUR_SCHEMA.YOUR_TABLE\n);\n\n--Apply to table\nALTER TABLE YOUR_DATABASE.YOUR_SCHEMA.YOUR_TABLE\n  ADD DATA METRIC FUNCTION SNOWFLAKE.CORE.DUPLICATE_COUNT\n    ON (account_number);\n</code></pre>"},{"location":"data-quality-tests-snowflake-only/#unique-combination-of-columns","title":"Unique Combination of Columns","text":"<p>Requires custom DMF. Currently DMFs require an explicit definition of the input columns and their data types. There isn't a way to create a single generic DMF that can handle varying numbers of columns or different data types. So must create a different DMF for each varying number and datatype of columns that make up composite keys in your tables. For example:</p> <p>unique_combo_2_strings (ARG_T table(ARG_C1 STRING, ARG_C2 STRING)) unique_combo_3_mixed (ARG_T table(ARG_C1 STRING, ARG_C2 NUMBER, ARG_C3 NUMBER ))</p> Unique combination of columns<pre><code>--Create custom DMF\nCREATE DATA METRIC FUNCTION IF NOT EXISTS\n  unique_combination_of_columns_2_strings (ARG_T table(ARG_C1 STRING, ARG_C2 STRING))\n  RETURNS NUMBER AS\n  'select count(1) from (\nselect ARG_C1, ARG_C2\nfrom ARG_T\ngroup by ARG_C1, ARG_C2\nhaving count(1) &gt; 1)'\n\n--Apply to table\nALTER TABLE customers ADD DATA METRIC FUNCTION\n  unique_combination_of_columns_2_strings ON (last_name, city);\n</code></pre>"},{"location":"data-quality-tests-snowflake-only/#referential-integrity","title":"Referential Integrity","text":"Referential integrity test<pre><code>--Create custom DMF\nCREATE OR REPLACE DATA METRIC FUNCTION referential_check(\n  arg_t1 TABLE (arg_c1 INT), arg_t2 TABLE (arg_c2 INT))\nRETURNS NUMBER AS\n 'SELECT COUNT(*) FROM arg_t1\n  WHERE arg_c1 NOT IN (SELECT arg_c2 FROM arg_t2)';\n\n--Apply to table\nALTER TABLE customers\n  ADD DATA METRIC FUNCTION referential_check\n    ON (account_number, TABLE (accounts(account_no)));\n</code></pre>"},{"location":"data-quality-tests-snowflake-only/#equal-rowcount","title":"Equal Rowcount","text":"<p>Note that for custom DMFs you must specify the column in the table argument, even if you don't use it in the function logic. This is a current limitation of the DMF framework. So this custom DMF takes in columns for each table although they are irrelevent for the test.</p> referential integrity<pre><code>--Create custom DMF. Note expects column names despite their irrelevance for this test\n--Note the result will be negative if table arg_t2 has more rows. \nCREATE OR REPLACE DATA METRIC FUNCTION equal_rowcout(\n  arg_t1 TABLE (arg_c1 INT), arg_t2 TABLE (arg_c2 INT))\nRETURNS NUMBER AS\n 'select (select count(1) from arg_t1) - (select count(1) from arg_t2)';\n\n--Apply to table: Note must pass column names despite their irrelevance for this test\nALTER TABLE customers\n  ADD DATA METRIC FUNCTION equal_rowcout\n    ON (account_number, TABLE (accounts(account_no)));\n</code></pre>"},{"location":"data-quality-tests-snowflake-only/#dmf-configuration","title":"DMF Configuration","text":"<p>See Reference documentation for more details</p> <pre><code>--See DMF's added to table\nSELECT * FROM TABLE(INFORMATION_SCHEMA.DATA_METRIC_FUNCTION_REFERENCES(\n  REF_ENTITY_NAME =&gt; 'YOUR_DATABASE.YOUR_SCHEMA.YOUR_TABLE',\n  REF_ENTITY_DOMAIN =&gt; 'TABLE'));\n\n--See all DMFs both system and custom\nSHOW DATA METRIC FUNCTIONS IN ACCOUNT;\n\n--Drop a DMF: Must get signature right for DMF or will get a \u201cdoes not exist\u201d error:\nDROP FUNCTION YOUR_DATABASE.YOUR_SCHEMA.YOUR_CUSTOM_DMF (table(STRING))\nDROP FUNCTION YOUR_DATABASE.YOUR_SCHEMA.YOUR_CUSTOM_DMF (table(STRING, STRING)) -\u2013e.g diff signature\n\n--View DMF results\nSELECT scheduled_time, measurement_time, table_name, metric_name, value\nFROM SNOWFLAKE.LOCAL.DATA_QUALITY_MONITORING_RESULTS\nWHERE TRUE\n-- AND METRIC_NAME = 'INVALID_EMAIL_COUNT'\n-- AND METRIC_DATABASE = 'DQ_TUTORIAL_DB'\norder by scheduled_time desc\nLIMIT 100;\n</code></pre>"},{"location":"data-quality-tests-snowflake-only/#reference-documentation","title":"Reference Documentation","text":"<p>Data Quality Monitoring</p> <p>Schedule your DMFs to run</p> <p>System DMFs</p> <p>DMF required parameters</p>"},{"location":"snowflake-tasks-and-streams-for-data-quality/","title":"Snowflake Tasks and Streams for Data Quality","text":""},{"location":"snowflake-tasks-and-streams-for-data-quality/#streams","title":"Streams","text":"<p>Capture and track changes to tables, providing a way to monitor data transformations and identify potential quality issues in real-time. </p>"},{"location":"snowflake-tasks-and-streams-for-data-quality/#tasks","title":"Tasks","text":"<p>Automate the execution of SQL queries and stored procedures, including data quality checks, on a predefined schedule or based on changes in a stream. </p>"},{"location":"snowflake-tasks-and-streams-for-data-quality/#example-workflow","title":"Example Workflow","text":"<ul> <li>A stream is created on a source table to capture data changes. </li> <li>A task is defined to run a data quality check on the stream's data whenever changes are detected. </li> <li>The task can utilize DMFs or custom UDFs to perform specific quality checks, such as checking for null values or duplicate entries. </li> <li>Based on the check results, actions can be taken, such as logging errors, alerting users, or retrying the transformation process. </li> </ul>"},{"location":"soda-example-yaml/","title":"Soda Example YAML Checks","text":"<pre><code>checks for dim_customers:\n  # Schema Contract\n  - schema:\n      name: Enforce contract schema\n      warn:\n        when required column missing: [customer_id, name, email]\n        when wrong column type:\n          customer_id: integer\n          email: varchar\n  # Data Quality Contract\n  - missing_count(email) = 0:\n      name: Emails must never be null\n  - invalid_percent(email) &lt; 1%:\n      name: Emails must be valid (regex)\n      valid regex: '^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n  - freshness(updated_at) &lt; 1d:\n      name: Data must be updated daily\n</code></pre>"}]}